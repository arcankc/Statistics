# =============================================================================
# Dermatoloji UzmanlÄ±k Tezi - KapsamlÄ± Veri Analizi
# arcankc - 2025-09-23 12:27:58 UTC
#
# Ã–ZELLIKLER:
# - Model vs Uzman vs Asistan karÅŸÄ±laÅŸtÄ±rmasÄ±
# - Deneyim sÃ¼resi ile baÅŸarÄ± oranÄ± analizi
# - SÄ±nÄ±f bazlÄ± detaylÄ± analizler
# - Veri dengesizliÄŸi Ã¶nlemleri
# - TÃ¼rkÃ§e aÃ§Ä±klamalar ve gÃ¶rselleÅŸtirmeler
# - KapsamlÄ± istatistiksel testler
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from pathlib import Path
from datetime import datetime
import json
import os

# Ä°statistiksel testler iÃ§in
from scipy import stats
from scipy.stats import chi2_contingency, fisher_exact, mannwhitneyu, kruskal
from statsmodels.stats.contingency_tables import mcnemar
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, \
    classification_report
from sklearn.metrics import cohen_kappa_score, matthews_corrcoef
from sklearn.utils.class_weight import compute_class_weight

# TÃ¼rkÃ§e karakter desteÄŸi
plt.rcParams['font.family'] = 'DejaVu Sans'
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================
CONFIG = {
    'paths': {
        'base_dir': r'C:\Users\kivan\Desktop\TEZ ANALÄ°Z\Python ile Veri Analizi',
        'model_results': r'C:\Users\kivan\Desktop\TEZ ANALÄ°Z\Python ile Veri Analizi\detailed_results.csv',
        'participant_results': r'C:\Users\kivan\Desktop\TEZ ANALÄ°Z\Python ile Veri Analizi\Quiz SonuÃ§larÄ± v2.xlsx',
        'output_dir': r'C:\Users\kivan\Desktop\TEZ ANALÄ°Z\Python ile Veri Analizi\Analiz_Sonuclari'
    },

    'classes': {
        'ak': 'Aktinik Keratoz',
        'bcc': 'Bazal HÃ¼creli Karsinom',
        'bkl': 'Benign Keratoz',
        'df': 'Dermatofibrom',
        'mel': 'Melanom',
        'nv': 'NevÃ¼s',
        'vasc': 'VaskÃ¼ler Lezyon',
        'scc': 'SkuamÃ¶z HÃ¼creli Karsinom'
    },

    'colors': {
        'uzman': '#2E86AB',  # Mavi
        'asistan': '#A23B72',  # Mor
        'model': '#F18F01',  # Turuncu
        'success': '#2ECC71',  # YeÅŸil
        'error': '#E74C3C',  # KÄ±rmÄ±zÄ±
        'neutral': '#95A5A6'  # Gri
    },

    'participant_mapping': {
        'experience_groups': {
            'Uzman': ['Prof. Dr.', 'DoÃ§. Dr.', 'Dr. Ã–ÄŸr. Ãœyesi', 'Uzman Dr.'],
            'Asistan': ['Asistan Dr.', 'AraÅŸtÄ±rma GÃ¶revlisi']
        }
    }
}


# =============================================================================
# DATA LOADING AND PREPROCESSING
# =============================================================================
class DataProcessor:
    """Veri yÃ¼kleme ve Ã¶n iÅŸleme sÄ±nÄ±fÄ±"""

    def __init__(self):
        self.model_data = None
        self.participant_data = None
        self.merged_data = None

    def load_data(self):
        """Veri dosyalarÄ±nÄ± yÃ¼kle"""
        print("ğŸ“ Veri dosyalarÄ± yÃ¼kleniyor...")

        try:
            # Model sonuÃ§larÄ±nÄ± yÃ¼kle
            self.model_data = pd.read_csv(CONFIG['paths']['model_results'])
            print(f"âœ… Model verileri yÃ¼klendi: {len(self.model_data)} kayÄ±t")

            # KatÄ±lÄ±mcÄ± sonuÃ§larÄ±nÄ± yÃ¼kle
            self.participant_data = pd.read_excel(CONFIG['paths']['participant_results'])
            print(f"âœ… KatÄ±lÄ±mcÄ± verileri yÃ¼klendi: {len(self.participant_data)} kayÄ±t")

            return True

        except Exception as e:
            print(f"âŒ Veri yÃ¼kleme hatasÄ±: {e}")
            return False

    def preprocess_model_data(self):
        """Model verilerini Ã¶n iÅŸle"""
        print("ğŸ”§ Model verileri iÅŸleniyor...")

        # Model baÅŸarÄ± durumunu hesapla
        if 'CNN + TTA_correct' in self.model_data.columns:
            self.model_data['model_correct'] = self.model_data['CNN + TTA_correct']
        elif 'LightGBM_correct' in self.model_data.columns:
            self.model_data['model_correct'] = self.model_data['LightGBM_correct']
        else:
            # Ä°lk mevcut model sonucunu kullan
            correct_cols = [col for col in self.model_data.columns if col.endswith('_correct')]
            if correct_cols:
                self.model_data['model_correct'] = self.model_data[correct_cols[0]]

        # SÄ±nÄ±f bilgilerini dÃ¼zenle
        if 'correct_diagnosis_mapped' in self.model_data.columns:
            self.model_data['true_class'] = self.model_data['correct_diagnosis_mapped']
        elif 'dx' in self.model_data.columns:
            self.model_data['true_class'] = self.model_data['dx']

        print(f"âœ… Model verileri iÅŸlendi. Model baÅŸarÄ± oranÄ±: {self.model_data['model_correct'].mean():.3f}")

    def preprocess_participant_data(self):
        """KatÄ±lÄ±mcÄ± verilerini Ã¶n iÅŸle"""
        print("ğŸ”§ KatÄ±lÄ±mcÄ± verileri iÅŸleniyor...")

        # Gerekli sÃ¼tunlarÄ± kontrol et ve oluÅŸtur
        required_columns = ['participant_id', 'question_id', 'participant_answer', 'correct_answer',
                            'is_correct', 'experience_level', 'experience_years']

        missing_columns = [col for col in required_columns if col not in self.participant_data.columns]
        if missing_columns:
            print(f"âš ï¸ Eksik sÃ¼tunlar: {missing_columns}")
            # Alternatif sÃ¼tun isimlerini dene
            self._map_alternative_columns()

        # Deneyim gruplarÄ±nÄ± oluÅŸtur
        self._create_experience_groups()

        # BaÅŸarÄ± oranlarÄ±nÄ± hesapla
        self._calculate_success_rates()

        print(f"âœ… KatÄ±lÄ±mcÄ± verileri iÅŸlendi. Toplam katÄ±lÄ±mcÄ±: {self.participant_data['participant_id'].nunique()}")

    def _map_alternative_columns(self):
        """Alternatif sÃ¼tun isimlerini eÅŸleÅŸtir"""
        column_mappings = {
            'participant_id': ['id', 'user_id', 'katilimci_id'],
            'question_id': ['soru_id', 'question', 'q_id'],
            'participant_answer': ['answer', 'cevap', 'secim'],
            'correct_answer': ['dogru_cevap', 'correct', 'true_answer'],
            'is_correct': ['dogru_mu', 'correct', 'basarili'],
            'experience_level': ['unvan', 'level', 'seviye'],
            'experience_years': ['yil', 'years', 'deneyim']
        }

        for target_col, alternatives in column_mappings.items():
            if target_col not in self.participant_data.columns:
                for alt in alternatives:
                    if alt in self.participant_data.columns:
                        self.participant_data[target_col] = self.participant_data[alt]
                        print(f"ğŸ“ {alt} -> {target_col} eÅŸleÅŸtirildi")
                        break

    def _create_experience_groups(self):
        """Deneyim gruplarÄ±nÄ± oluÅŸtur"""
        if 'experience_level' in self.participant_data.columns:
            # Unvan bazlÄ± gruplandÄ±rma
            self.participant_data['group'] = 'DiÄŸer'

            for group, titles in CONFIG['participant_mapping']['experience_groups'].items():
                mask = self.participant_data['experience_level'].isin(titles)
                self.participant_data.loc[mask, 'group'] = group

        elif 'experience_years' in self.participant_data.columns:
            # YÄ±l bazlÄ± gruplandÄ±rma
            self.participant_data['group'] = pd.cut(
                self.participant_data['experience_years'],
                bins=[0, 2, 5, 10, 100],
                labels=['0-2 YÄ±l', '3-5 YÄ±l', '6-10 YÄ±l', '10+ YÄ±l']
            )

    def _calculate_success_rates(self):
        """BaÅŸarÄ± oranlarÄ±nÄ± hesapla"""
        if 'is_correct' not in self.participant_data.columns:
            if 'participant_answer' in self.participant_data.columns and 'correct_answer' in self.participant_data.columns:
                self.participant_data['is_correct'] = (
                        self.participant_data['participant_answer'] == self.participant_data['correct_answer']
                )

    def merge_data(self):
        """Model ve katÄ±lÄ±mcÄ± verilerini birleÅŸtir"""
        print("ğŸ”— Veriler birleÅŸtiriliyor...")

        try:
            # Question ID'ye gÃ¶re birleÅŸtir
            if 'question_id' in self.model_data.columns and 'question_id' in self.participant_data.columns:
                self.merged_data = pd.merge(
                    self.participant_data,
                    self.model_data[['question_id', 'model_correct', 'true_class']],
                    on='question_id',
                    how='left'
                )
            else:
                print("âš ï¸ Question ID eÅŸleÅŸtirmesi yapÄ±lamadÄ±, ayrÄ± analizler yapÄ±lacak")

            print(f"âœ… Veriler birleÅŸtirildi: {len(self.merged_data) if self.merged_data is not None else 0} kayÄ±t")

        except Exception as e:
            print(f"âŒ Veri birleÅŸtirme hatasÄ±: {e}")


# =============================================================================
# STATISTICAL ANALYSIS CLASS
# =============================================================================
class StatisticalAnalyzer:
    """Ä°statistiksel analiz sÄ±nÄ±fÄ±"""

    def __init__(self, data_processor):
        self.dp = data_processor
        self.results = {}

    def analyze_overall_performance(self):
        """Genel performans analizi"""
        print("\nğŸ“Š Genel performans analizi yapÄ±lÄ±yor...")

        results = {}

        # Model performansÄ±
        if self.dp.model_data is not None:
            model_accuracy = self.dp.model_data['model_correct'].mean()
            results['model'] = {
                'accuracy': model_accuracy,
                'total_questions': len(self.dp.model_data),
                'correct_answers': self.dp.model_data['model_correct'].sum()
            }

        # KatÄ±lÄ±mcÄ± performansÄ±
        if self.dp.participant_data is not None:
            participant_stats = self.dp.participant_data.groupby('participant_id')['is_correct'].agg(
                ['mean', 'count', 'sum'])

            results['participants'] = {
                'average_accuracy': participant_stats['mean'].mean(),
                'std_accuracy': participant_stats['mean'].std(),
                'min_accuracy': participant_stats['mean'].min(),
                'max_accuracy': participant_stats['mean'].max(),
                'total_participants': len(participant_stats)
            }

        # Grup karÅŸÄ±laÅŸtÄ±rmasÄ±
        if 'group' in self.dp.participant_data.columns:
            group_stats = self.dp.participant_data.groupby('group')['is_correct'].agg(['mean', 'count', 'std'])
            results['groups'] = group_stats.to_dict()

        self.results['overall'] = results
        return results

    def analyze_class_wise_performance(self):
        """SÄ±nÄ±f bazlÄ± performans analizi"""
        print("\nğŸ“Š SÄ±nÄ±f bazlÄ± performans analizi yapÄ±lÄ±yor...")

        results = {}

        # Model sÄ±nÄ±f performansÄ±
        if self.dp.model_data is not None and 'true_class' in self.dp.model_data.columns:
            model_class_stats = self.dp.model_data.groupby('true_class')['model_correct'].agg(['mean', 'count', 'sum'])
            results['model'] = model_class_stats.to_dict()

        # KatÄ±lÄ±mcÄ± sÄ±nÄ±f performansÄ±
        if self.dp.merged_data is not None:
            participant_class_stats = self.dp.merged_data.groupby(['true_class', 'group'])['is_correct'].agg(
                ['mean', 'count'])
            results['participants'] = participant_class_stats.to_dict()

        self.results['class_wise'] = results
        return results

    def statistical_tests(self):
        """Ä°statistiksel testler"""
        print("\nğŸ“Š Ä°statistiksel testler yapÄ±lÄ±yor...")

        results = {}

        if self.dp.merged_data is not None:
            # Uzman vs Asistan karÅŸÄ±laÅŸtÄ±rmasÄ±
            uzman_data = self.dp.merged_data[self.dp.merged_data['group'] == 'Uzman']['is_correct']
            asistan_data = self.dp.merged_data[self.dp.merged_data['group'] == 'Asistan']['is_correct']

            if len(uzman_data) > 0 and len(asistan_data) > 0:
                # Mann-Whitney U testi
                u_stat, u_p = mannwhitneyu(uzman_data, asistan_data, alternative='two-sided')
                results['uzman_vs_asistan'] = {
                    'test': 'Mann-Whitney U',
                    'u_statistic': u_stat,
                    'p_value': u_p,
                    'significant': u_p < 0.05,
                    'uzman_mean': uzman_data.mean(),
                    'asistan_mean': asistan_data.mean()
                }

            # Model vs Ä°nsan karÅŸÄ±laÅŸtÄ±rmasÄ±
            human_accuracy = self.dp.merged_data.groupby('question_id')['is_correct'].mean()
            model_accuracy = self.dp.merged_data.groupby('question_id')['model_correct'].first()

            # Soru bazlÄ± karÅŸÄ±laÅŸtÄ±rma
            if len(human_accuracy) > 0 and len(model_accuracy) > 0:
                common_questions = human_accuracy.index.intersection(model_accuracy.index)
                if len(common_questions) > 0:
                    human_acc_common = human_accuracy.loc[common_questions]
                    model_acc_common = model_accuracy.loc[common_questions]

                    # Paired t-test
                    t_stat, t_p = stats.ttest_rel(human_acc_common, model_acc_common)
                    results['model_vs_human'] = {
                        'test': 'Paired t-test',
                        't_statistic': t_stat,
                        'p_value': t_p,
                        'significant': t_p < 0.05,
                        'human_mean': human_acc_common.mean(),
                        'model_mean': model_acc_common.mean()
                    }

        self.results['statistical_tests'] = results
        return results

    def experience_analysis(self):
        """Deneyim analizi"""
        print("\nğŸ“Š Deneyim analizi yapÄ±lÄ±yor...")

        results = {}

        if 'experience_years' in self.dp.participant_data.columns:
            # Deneyim yÄ±lÄ± ile baÅŸarÄ± oranÄ± korelasyonu
            participant_stats = self.dp.participant_data.groupby('participant_id').agg({
                'is_correct': 'mean',
                'experience_years': 'first'
            })

            correlation, cor_p = stats.pearsonr(participant_stats['experience_years'], participant_stats['is_correct'])

            results['experience_correlation'] = {
                'correlation': correlation,
                'p_value': cor_p,
                'significant': cor_p < 0.05
            }

            # Deneyim gruplarÄ± arasÄ± karÅŸÄ±laÅŸtÄ±rma
            if 'group' in self.dp.participant_data.columns:
                groups = self.dp.participant_data['group'].unique()
                group_accuracies = []

                for group in groups:
                    group_data = self.dp.participant_data[self.dp.participant_data['group'] == group]
                    group_acc = group_data.groupby('participant_id')['is_correct'].mean()
                    group_accuracies.append(group_acc.values)

                if len(group_accuracies) > 1:
                    # Kruskal-Wallis testi
                    h_stat, h_p = kruskal(*group_accuracies)
                    results['group_comparison'] = {
                        'test': 'Kruskal-Wallis',
                        'h_statistic': h_stat,
                        'p_value': h_p,
                        'significant': h_p < 0.05
                    }

        self.results['experience'] = results
        return results


# =============================================================================
# VISUALIZATION CLASS
# =============================================================================
class Visualizer:
    """GÃ¶rselleÅŸtirme sÄ±nÄ±fÄ±"""

    def __init__(self, data_processor, analyzer):
        self.dp = data_processor
        self.analyzer = analyzer
        self.output_dir = Path(CONFIG['paths']['output_dir'])
        self.output_dir.mkdir(exist_ok=True)

    def create_overall_comparison(self):
        """Genel karÅŸÄ±laÅŸtÄ±rma grafiÄŸi"""
        print("ğŸ“Š Genel karÅŸÄ±laÅŸtÄ±rma grafiÄŸi oluÅŸturuluyor...")

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Dermatoloji Testi - Genel Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=16, fontweight='bold')

        # 1. Model vs KatÄ±lÄ±mcÄ± baÅŸarÄ± oranlarÄ±
        if 'overall' in self.analyzer.results:
            ax1 = axes[0, 0]

            model_acc = self.analyzer.results['overall'].get('model', {}).get('accuracy', 0)
            human_acc = self.analyzer.results['overall'].get('participants', {}).get('average_accuracy', 0)

            categories = ['Model\n(AI)', 'Ä°nsan\n(Ortalama)']
            accuracies = [model_acc, human_acc]
            colors = [CONFIG['colors']['model'], CONFIG['colors']['neutral']]

            bars = ax1.bar(categories, accuracies, color=colors, alpha=0.8)
            ax1.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax1.set_title('Model vs Ä°nsan PerformansÄ±')
            ax1.set_ylim(0, 1)

            # DeÄŸerleri gÃ¶ster
            for bar, acc in zip(bars, accuracies):
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                         f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

        # 2. Uzman vs Asistan karÅŸÄ±laÅŸtÄ±rmasÄ±
        if 'group' in self.dp.participant_data.columns:
            ax2 = axes[0, 1]

            group_stats = self.dp.participant_data.groupby('group')['is_correct'].mean()

            bars = ax2.bar(group_stats.index, group_stats.values,
                           color=[CONFIG['colors']['uzman'], CONFIG['colors']['asistan']], alpha=0.8)
            ax2.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax2.set_title('Uzman vs Asistan PerformansÄ±')
            ax2.set_ylim(0, 1)

            for bar, val in zip(bars, group_stats.values):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                         f'{val:.3f}', ha='center', va='bottom', fontweight='bold')

        # 3. SÄ±nÄ±f bazlÄ± baÅŸarÄ± oranlarÄ±
        if self.dp.merged_data is not None:
            ax3 = axes[1, 0]

            class_stats = self.dp.merged_data.groupby('true_class')['is_correct'].mean().sort_values()

            bars = ax3.barh(range(len(class_stats)), class_stats.values, color=CONFIG['colors']['success'], alpha=0.7)
            ax3.set_yticks(range(len(class_stats)))
            ax3.set_yticklabels([CONFIG['classes'].get(cls, cls) for cls in class_stats.index])
            ax3.set_xlabel('BaÅŸarÄ± OranÄ±')
            ax3.set_title('HastalÄ±k SÄ±nÄ±fÄ± BazlÄ± BaÅŸarÄ± OranlarÄ±')

            for i, val in enumerate(class_stats.values):
                ax3.text(val + 0.01, i, f'{val:.3f}', va='center', fontweight='bold')

        # 4. KatÄ±lÄ±mcÄ± baÅŸarÄ± daÄŸÄ±lÄ±mÄ±
        if self.dp.participant_data is not None:
            ax4 = axes[1, 1]

            participant_accuracies = self.dp.participant_data.groupby('participant_id')['is_correct'].mean()

            ax4.hist(participant_accuracies, bins=20, color=CONFIG['colors']['neutral'], alpha=0.7, edgecolor='black')
            ax4.axvline(participant_accuracies.mean(), color=CONFIG['colors']['error'],
                        linestyle='--', linewidth=2, label=f'Ortalama: {participant_accuracies.mean():.3f}')
            ax4.set_xlabel('BaÅŸarÄ± OranÄ±')
            ax4.set_ylabel('KatÄ±lÄ±mcÄ± SayÄ±sÄ±')
            ax4.set_title('KatÄ±lÄ±mcÄ± BaÅŸarÄ± OranÄ± DaÄŸÄ±lÄ±mÄ±')
            ax4.legend()

        plt.tight_layout()
        plt.savefig(self.output_dir / 'genel_karsilastirma.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… Genel karÅŸÄ±laÅŸtÄ±rma grafiÄŸi kaydedildi: {self.output_dir / 'genel_karsilastirma.png'}")

    def create_class_wise_analysis(self):
        """SÄ±nÄ±f bazlÄ± detaylÄ± analiz"""
        print("ğŸ“Š SÄ±nÄ±f bazlÄ± analiz grafiÄŸi oluÅŸturuluyor...")

        if self.dp.merged_data is None:
            print("âš ï¸ BirleÅŸtirilmiÅŸ veri bulunamadÄ±, sÄ±nÄ±f bazlÄ± analiz atlanÄ±yor")
            return

        # SÄ±nÄ±f sayÄ±sÄ±na gÃ¶re grid boyutunu belirle
        n_classes = len(CONFIG['classes'])
        ncols = 3
        nrows = (n_classes + ncols - 1) // ncols

        fig, axes = plt.subplots(nrows, ncols, figsize=(18, 6 * nrows))
        fig.suptitle('HastalÄ±k SÄ±nÄ±fÄ± BazlÄ± DetaylÄ± Performans Analizi', fontsize=16, fontweight='bold')

        if nrows == 1:
            axes = axes.reshape(1, -1)

        class_list = list(CONFIG['classes'].keys())

        for idx, class_code in enumerate(class_list):
            row = idx // ncols
            col = idx % ncols
            ax = axes[row, col]

            class_data = self.dp.merged_data[self.dp.merged_data['true_class'] == class_code]

            if len(class_data) > 0:
                # Model vs Grup karÅŸÄ±laÅŸtÄ±rmasÄ±
                model_acc = class_data['model_correct'].mean()
                group_stats = class_data.groupby('group')['is_correct'].mean()

                # Bar plot
                categories = ['Model'] + list(group_stats.index)
                accuracies = [model_acc] + list(group_stats.values)
                colors = [CONFIG['colors']['model']] + [
                    CONFIG['colors']['uzman'] if 'Uzman' in cat else CONFIG['colors']['asistan'] for cat in
                    group_stats.index]

                bars = ax.bar(categories, accuracies, color=colors, alpha=0.8)
                ax.set_title(f'{CONFIG["classes"][class_code]}\n({len(class_data)} soru)', fontweight='bold')
                ax.set_ylabel('BaÅŸarÄ± OranÄ±')
                ax.set_ylim(0, 1)

                # DeÄŸerleri gÃ¶ster
                for bar, acc in zip(bars, accuracies):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width() / 2., height + 0.02,
                            f'{acc:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

                # X etiketlerini dÃ¶ndÃ¼r
                ax.tick_params(axis='x', rotation=45)
            else:
                ax.text(0.5, 0.5, 'Veri Yok', ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f'{CONFIG["classes"][class_code]}', fontweight='bold')

        # BoÅŸ grafikleri gizle
        for idx in range(n_classes, nrows * ncols):
            row = idx // ncols
            col = idx % ncols
            axes[row, col].set_visible(False)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'sinif_bazli_analiz.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… SÄ±nÄ±f bazlÄ± analiz grafiÄŸi kaydedildi: {self.output_dir / 'sinif_bazli_analiz.png'}")

    def create_confusion_matrices(self):
        """KarÄ±ÅŸÄ±klÄ±k matrisleri"""
        print("ğŸ“Š KarÄ±ÅŸÄ±klÄ±k matrisleri oluÅŸturuluyor...")

        if self.dp.merged_data is None:
            print("âš ï¸ BirleÅŸtirilmiÅŸ veri bulunamadÄ±, karÄ±ÅŸÄ±klÄ±k matrisleri atlanÄ±yor")
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle('KarÄ±ÅŸÄ±klÄ±k Matrisleri KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=16, fontweight='bold')

        class_labels = [CONFIG['classes'][cls] for cls in CONFIG['classes'].keys()]

        # 1. Model karÄ±ÅŸÄ±klÄ±k matrisi
        if 'model_correct' in self.dp.merged_data.columns:
            # Model predictions vs true labels
            y_true = self.dp.merged_data['true_class']
            # Bu Ã¶rnek iÃ§in model_correct boolean, gerÃ§ek implementation'da prediction labels olacak
            y_pred_model = self.dp.merged_data['true_class'].where(self.dp.merged_data['model_correct'], 'wrong')

            # Sadece doÄŸru tahminleri gÃ¶ster (basitleÅŸtirilmiÅŸ)
            model_accuracy = self.dp.merged_data.groupby('true_class')['model_correct'].mean()

            ax1 = axes[0]
            bars = ax1.bar(range(len(model_accuracy)), model_accuracy.values, color=CONFIG['colors']['model'],
                           alpha=0.8)
            ax1.set_title('Model SÄ±nÄ±f BazlÄ± BaÅŸarÄ±', fontweight='bold')
            ax1.set_xlabel('HastalÄ±k SÄ±nÄ±fÄ±')
            ax1.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax1.set_xticks(range(len(model_accuracy)))
            ax1.set_xticklabels([CONFIG['classes'][cls] for cls in model_accuracy.index], rotation=45, ha='right')

            for bar, val in zip(bars, model_accuracy.values):
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                         f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

        # 2. Uzman karÄ±ÅŸÄ±klÄ±k matrisi
        uzman_data = self.dp.merged_data[self.dp.merged_data['group'] == 'Uzman']
        if len(uzman_data) > 0:
            uzman_accuracy = uzman_data.groupby('true_class')['is_correct'].mean()

            ax2 = axes[1]
            bars = ax2.bar(range(len(uzman_accuracy)), uzman_accuracy.values, color=CONFIG['colors']['uzman'],
                           alpha=0.8)
            ax2.set_title('Uzman SÄ±nÄ±f BazlÄ± BaÅŸarÄ±', fontweight='bold')
            ax2.set_xlabel('HastalÄ±k SÄ±nÄ±fÄ±')
            ax2.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax2.set_xticks(range(len(uzman_accuracy)))
            ax2.set_xticklabels([CONFIG['classes'][cls] for cls in uzman_accuracy.index], rotation=45, ha='right')

            for bar, val in zip(bars, uzman_accuracy.values):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                         f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

        # 3. Asistan karÄ±ÅŸÄ±klÄ±k matrisi
        asistan_data = self.dp.merged_data[self.dp.merged_data['group'] == 'Asistan']
        if len(asistan_data) > 0:
            asistan_accuracy = asistan_data.groupby('true_class')['is_correct'].mean()

            ax3 = axes[2]
            bars = ax3.bar(range(len(asistan_accuracy)), asistan_accuracy.values, color=CONFIG['colors']['asistan'],
                           alpha=0.8)
            ax3.set_title('Asistan SÄ±nÄ±f BazlÄ± BaÅŸarÄ±', fontweight='bold')
            ax3.set_xlabel('HastalÄ±k SÄ±nÄ±fÄ±')
            ax3.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax3.set_xticks(range(len(asistan_accuracy)))
            ax3.set_xticklabels([CONFIG['classes'][cls] for cls in asistan_accuracy.index], rotation=45, ha='right')

            for bar, val in zip(bars, asistan_accuracy.values):
                height = bar.get_height()
                ax3.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                         f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'karisikhk_matrisleri.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… KarÄ±ÅŸÄ±klÄ±k matrisleri kaydedildi: {self.output_dir / 'karisikhk_matrisleri.png'}")

    def create_experience_analysis(self):
        """Deneyim analizi grafikleri"""
        print("ğŸ“Š Deneyim analizi grafikleri oluÅŸturuluyor...")

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Deneyim SÃ¼resi ve BaÅŸarÄ± OranÄ± Analizi', fontsize=16, fontweight='bold')

        # 1. Deneyim yÄ±lÄ± vs baÅŸarÄ± oranÄ± scatter plot
        if 'experience_years' in self.dp.participant_data.columns:
            ax1 = axes[0, 0]

            participant_stats = self.dp.participant_data.groupby('participant_id').agg({
                'is_correct': 'mean',
                'experience_years': 'first',
                'group': 'first'
            })

            for group in participant_stats['group'].unique():
                group_data = participant_stats[participant_stats['group'] == group]
                color = CONFIG['colors']['uzman'] if group == 'Uzman' else CONFIG['colors']['asistan']
                ax1.scatter(group_data['experience_years'], group_data['is_correct'],
                            color=color, alpha=0.7, label=group, s=50)

            # Trend line
            if len(participant_stats) > 1:
                z = np.polyfit(participant_stats['experience_years'], participant_stats['is_correct'], 1)
                p = np.poly1d(z)
                ax1.plot(participant_stats['experience_years'], p(participant_stats['experience_years']),
                         "r--", alpha=0.8, linewidth=2)

            ax1.set_xlabel('Deneyim YÄ±lÄ±')
            ax1.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax1.set_title('Deneyim YÄ±lÄ± vs BaÅŸarÄ± OranÄ±')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

        # 2. Deneyim gruplarÄ± boxplot
        if 'group' in self.dp.participant_data.columns:
            ax2 = axes[0, 1]

            participant_accuracies = self.dp.participant_data.groupby(['participant_id', 'group'])[
                'is_correct'].mean().reset_index()

            groups = participant_accuracies['group'].unique()
            group_data = [participant_accuracies[participant_accuracies['group'] == group]['is_correct'] for group in
                          groups]

            bp = ax2.boxplot(group_data, labels=groups, patch_artist=True)

            colors = [CONFIG['colors']['uzman'] if 'Uzman' in group else CONFIG['colors']['asistan'] for group in
                      groups]
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)

            ax2.set_ylabel('BaÅŸarÄ± OranÄ±')
            ax2.set_title('Deneyim GruplarÄ± BaÅŸarÄ± DaÄŸÄ±lÄ±mÄ±')
            ax2.grid(True, alpha=0.3)

        # 3. Soru zorluÄŸu analizi
        if self.dp.merged_data is not None:
            ax3 = axes[1, 0]

            question_difficulty = self.dp.merged_data.groupby('question_id')['is_correct'].mean()

            ax3.hist(question_difficulty, bins=20, color=CONFIG['colors']['neutral'], alpha=0.7, edgecolor='black')
            ax3.axvline(question_difficulty.mean(), color=CONFIG['colors']['error'],
                        linestyle='--', linewidth=2, label=f'Ortalama: {question_difficulty.mean():.3f}')
            ax3.set_xlabel('Soru BaÅŸarÄ± OranÄ±')
            ax3.set_ylabel('Soru SayÄ±sÄ±')
            ax3.set_title('Soru ZorluÄŸu DaÄŸÄ±lÄ±mÄ±')
            ax3.legend()
            ax3.grid(True, alpha=0.3)

        # 4. Model vs Ä°nsan soru bazlÄ± karÅŸÄ±laÅŸtÄ±rma
        if self.dp.merged_data is not None:
            ax4 = axes[1, 1]

            question_stats = self.dp.merged_data.groupby('question_id').agg({
                'is_correct': 'mean',
                'model_correct': 'first'
            })

            ax4.scatter(question_stats['model_correct'], question_stats['is_correct'],
                        alpha=0.7, color=CONFIG['colors']['model'], s=50)
            ax4.plot([0, 1], [0, 1], 'r--', alpha=0.8, linewidth=2, label='EÅŸit Performans')
            ax4.set_xlabel('Model BaÅŸarÄ± OranÄ±')
            ax4.set_ylabel('Ä°nsan BaÅŸarÄ± OranÄ±')
            ax4.set_title('Soru BazlÄ± Model vs Ä°nsan KarÅŸÄ±laÅŸtÄ±rmasÄ±')
            ax4.legend()
            ax4.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_dir / 'deneyim_analizi.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… Deneyim analizi grafikleri kaydedildi: {self.output_dir / 'deneyim_analizi.png'}")

    def create_statistical_summary(self):
        """Ä°statistiksel Ã¶zet tablosu"""
        print("ğŸ“Š Ä°statistiksel Ã¶zet tablosu oluÅŸturuluyor...")

        fig, ax = plt.subplots(figsize=(12, 8))
        fig.suptitle('Ä°statistiksel Test SonuÃ§larÄ±', fontsize=16, fontweight='bold')

        # Tablo verilerini hazÄ±rla
        table_data = []

        if 'statistical_tests' in self.analyzer.results:
            tests = self.analyzer.results['statistical_tests']

            for test_name, test_results in tests.items():
                if test_name == 'uzman_vs_asistan':
                    table_data.append([
                        'Uzman vs Asistan',
                        f"{test_results.get('uzman_mean', 0):.3f}",
                        f"{test_results.get('asistan_mean', 0):.3f}",
                        f"{test_results.get('p_value', 0):.3f}",
                        'AnlamlÄ±' if test_results.get('significant', False) else 'AnlamlÄ± DeÄŸil'
                    ])
                elif test_name == 'model_vs_human':
                    table_data.append([
                        'Model vs Ä°nsan',
                        f"{test_results.get('model_mean', 0):.3f}",
                        f"{test_results.get('human_mean', 0):.3f}",
                        f"{test_results.get('p_value', 0):.3f}",
                        'AnlamlÄ±' if test_results.get('significant', False) else 'AnlamlÄ± DeÄŸil'
                    ])

        if table_data:
            columns = ['KarÅŸÄ±laÅŸtÄ±rma', 'Grup 1 Ort.', 'Grup 2 Ort.', 'p-deÄŸeri', 'AnlamlÄ±lÄ±k']

            table = ax.table(cellText=table_data, colLabels=columns,
                             cellLoc='center', loc='center')
            table.auto_set_font_size(False)
            table.set_fontsize(12)
            table.scale(1, 2)

            # Renklendirme
            for i in range(len(columns)):
                table[(0, i)].set_facecolor(CONFIG['colors']['neutral'])
                table[(0, i)].set_text_props(weight='bold', color='white')

            for i in range(1, len(table_data) + 1):
                for j in range(len(columns)):
                    if j == 4:  # AnlamlÄ±lÄ±k sÃ¼tunu
                        color = CONFIG['colors']['success'] if 'AnlamlÄ±' in table_data[i - 1][j] and 'DeÄŸil' not in \
                                                               table_data[i - 1][j] else CONFIG['colors']['error']
                        table[(i, j)].set_facecolor(color)
                        table[(i, j)].set_text_props(weight='bold', color='white')

        ax.axis('off')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'istatistiksel_ozet.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… Ä°statistiksel Ã¶zet tablosu kaydedildi: {self.output_dir / 'istatistiksel_ozet.png'}")


# =============================================================================
# REPORT GENERATOR
# =============================================================================
class ReportGenerator:
    """Rapor oluÅŸturucu sÄ±nÄ±fÄ±"""

    def __init__(self, data_processor, analyzer):
        self.dp = data_processor
        self.analyzer = analyzer
        self.output_dir = Path(CONFIG['paths']['output_dir'])

    def generate_comprehensive_report(self):
        """KapsamlÄ± rapor oluÅŸtur"""
        print("ğŸ“‹ KapsamlÄ± rapor oluÅŸturuluyor...")

        report_path = self.output_dir / 'dermatoloji_tezi_analiz_raporu.txt'

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("DERMATOLOJÄ° UZMANLIK TEZÄ° - KAPSAMLI VERÄ° ANALÄ°ZÄ° RAPORU\n")
            f.write("=" * 80 + "\n")
            f.write(f"Rapor Tarihi: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write(f"Analist: arcankc\n")
            f.write("=" * 80 + "\n\n")

            # Veri Ã¶zeti
            f.write("1. VERÄ° Ã–ZETÄ°\n")
            f.write("-" * 30 + "\n")

            if self.dp.model_data is not None:
                f.write(f"Model Test Verileri: {len(self.dp.model_data)} soru\n")
                f.write(f"Model BaÅŸarÄ± OranÄ±: {self.dp.model_data['model_correct'].mean():.3f}\n")

            if self.dp.participant_data is not None:
                f.write(f"KatÄ±lÄ±mcÄ± SayÄ±sÄ±: {self.dp.participant_data['participant_id'].nunique()}\n")
                f.write(f"Toplam Cevap: {len(self.dp.participant_data)}\n")
                f.write(f"Ortalama Ä°nsan BaÅŸarÄ± OranÄ±: {self.dp.participant_data['is_correct'].mean():.3f}\n")

            if 'group' in self.dp.participant_data.columns:
                group_counts = self.dp.participant_data['group'].value_counts()
                f.write(f"\nKatÄ±lÄ±mcÄ± DaÄŸÄ±lÄ±mÄ±:\n")
                for group, count in group_counts.items():
                    f.write(f"  {group}: {count} katÄ±lÄ±mcÄ±\n")

            # Genel performans
            f.write("\n2. GENEL PERFORMANS ANALÄ°ZÄ°\n")
            f.write("-" * 35 + "\n")

            if 'overall' in self.analyzer.results:
                overall = self.analyzer.results['overall']

                if 'model' in overall:
                    f.write(f"Model PerformansÄ±:\n")
                    f.write(
                        f"  DoÄŸru Cevap: {overall['model']['correct_answers']}/{overall['model']['total_questions']}\n")
                    f.write(f"  BaÅŸarÄ± OranÄ±: {overall['model']['accuracy']:.3f}\n\n")

                if 'participants' in overall:
                    f.write(f"KatÄ±lÄ±mcÄ± PerformansÄ±:\n")
                    f.write(f"  Ortalama BaÅŸarÄ±: {overall['participants']['average_accuracy']:.3f}\n")
                    f.write(f"  Standart Sapma: {overall['participants']['std_accuracy']:.3f}\n")
                    f.write(f"  En DÃ¼ÅŸÃ¼k: {overall['participants']['min_accuracy']:.3f}\n")
                    f.write(f"  En YÃ¼ksek: {overall['participants']['max_accuracy']:.3f}\n\n")

            # Ä°statistiksel testler
            f.write("3. Ä°STATÄ°STÄ°KSEL TEST SONUÃ‡LARI\n")
            f.write("-" * 35 + "\n")

            if 'statistical_tests' in self.analyzer.results:
                tests = self.analyzer.results['statistical_tests']

                for test_name, results in tests.items():
                    if test_name == 'uzman_vs_asistan':
                        f.write(f"Uzman vs Asistan KarÅŸÄ±laÅŸtÄ±rmasÄ±:\n")
                        f.write(f"  Test: {results['test']}\n")
                        f.write(f"  Uzman Ortalama: {results['uzman_mean']:.3f}\n")
                        f.write(f"  Asistan Ortalama: {results['asistan_mean']:.3f}\n")
                        f.write(f"  p-deÄŸeri: {results['p_value']:.3f}\n")
                        f.write(f"  AnlamlÄ±lÄ±k: {'AnlamlÄ±' if results['significant'] else 'AnlamlÄ± DeÄŸil'}\n\n")

                    elif test_name == 'model_vs_human':
                        f.write(f"Model vs Ä°nsan KarÅŸÄ±laÅŸtÄ±rmasÄ±:\n")
                        f.write(f"  Test: {results['test']}\n")
                        f.write(f"  Model Ortalama: {results['model_mean']:.3f}\n")
                        f.write(f"  Ä°nsan Ortalama: {results['human_mean']:.3f}\n")
                        f.write(f"  p-deÄŸeri: {results['p_value']:.3f}\n")
                        f.write(f"  AnlamlÄ±lÄ±k: {'AnlamlÄ±' if results['significant'] else 'AnlamlÄ± DeÄŸil'}\n\n")

            # SÄ±nÄ±f bazlÄ± analiz
            f.write("4. SINIF BAZLI PERFORMANS\n")
            f.write("-" * 30 + "\n")

            if 'class_wise' in self.analyzer.results:
                if self.dp.merged_data is not None:
                    class_performance = self.dp.merged_data.groupby('true_class').agg({
                        'is_correct': ['count', 'mean'],
                        'model_correct': 'mean'
                    })

                    f.write("HastalÄ±k SÄ±nÄ±fÄ± BazlÄ± BaÅŸarÄ± OranlarÄ±:\n")
                    f.write(f"{'SÄ±nÄ±f':<20} {'Soru SayÄ±sÄ±':<12} {'Ä°nsan':<8} {'Model':<8}\n")
                    f.write("-" * 50 + "\n")

                    for class_code in class_performance.index:
                        class_name = CONFIG['classes'].get(class_code, class_code)
                        count = class_performance.loc[class_code, ('is_correct', 'count')]
                        human_acc = class_performance.loc[class_code, ('is_correct', 'mean')]
                        model_acc = class_performance.loc[class_code, 'model_correct']

                        f.write(f"{class_name[:19]:<20} {count:<12} {human_acc:.3f}    {model_acc:.3f}\n")

            # Deneyim analizi
            f.write("\n5. DENEYÄ°M ANALÄ°ZÄ°\n")
            f.write("-" * 20 + "\n")

            if 'experience' in self.analyzer.results:
                exp_results = self.analyzer.results['experience']

                if 'experience_correlation' in exp_results:
                    corr = exp_results['experience_correlation']
                    f.write(f"Deneyim YÄ±lÄ± - BaÅŸarÄ± Korelasyonu:\n")
                    f.write(f"  Korelasyon KatsayÄ±sÄ±: {corr['correlation']:.3f}\n")
                    f.write(f"  p-deÄŸeri: {corr['p_value']:.3f}\n")
                    f.write(f"  AnlamlÄ±lÄ±k: {'AnlamlÄ±' if corr['significant'] else 'AnlamlÄ± DeÄŸil'}\n\n")

                if 'group_comparison' in exp_results:
                    group_comp = exp_results['group_comparison']
                    f.write(f"Deneyim GruplarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±:\n")
                    f.write(f"  Test: {group_comp['test']}\n")
                    f.write(f"  p-deÄŸeri: {group_comp['p_value']:.3f}\n")
                    f.write(f"  AnlamlÄ±lÄ±k: {'AnlamlÄ±' if group_comp['significant'] else 'AnlamlÄ± DeÄŸil'}\n\n")

            # SonuÃ§lar ve Ã¶neriler
            f.write("6. SONUÃ‡LAR VE Ã–NERÄ°LER\n")
            f.write("-" * 25 + "\n")

            f.write("Ana Bulgular:\n")

            # Model vs Ä°nsan karÅŸÄ±laÅŸtÄ±rmasÄ±
            if self.dp.model_data is not None and self.dp.participant_data is not None:
                model_acc = self.dp.model_data['model_correct'].mean()
                human_acc = self.dp.participant_data['is_correct'].mean()

                if model_acc > human_acc:
                    f.write(f"â€¢ Model ({model_acc:.3f}) insanlardan ({human_acc:.3f}) daha baÅŸarÄ±lÄ±\n")
                else:
                    f.write(f"â€¢ Ä°nsanlar ({human_acc:.3f}) modelden ({model_acc:.3f}) daha baÅŸarÄ±lÄ±\n")

            # Uzman vs Asistan
            if 'group' in self.dp.participant_data.columns:
                group_stats = self.dp.participant_data.groupby('group')['is_correct'].mean()
                if 'Uzman' in group_stats.index and 'Asistan' in group_stats.index:
                    uzman_acc = group_stats['Uzman']
                    asistan_acc = group_stats['Asistan']

                    if uzman_acc > asistan_acc:
                        f.write(f"â€¢ Uzmanlar ({uzman_acc:.3f}) asistanlardan ({asistan_acc:.3f}) daha baÅŸarÄ±lÄ±\n")
                    else:
                        f.write(f"â€¢ Asistanlar ({asistan_acc:.3f}) uzmanlardan ({uzman_acc:.3f}) daha baÅŸarÄ±lÄ±\n")

            f.write("\nÃ–neriler:\n")
            f.write("â€¢ Model performansÄ±nÄ±n yÃ¼ksek olduÄŸu alanlarda klinik karar desteÄŸi kullanÄ±labilir\n")
            f.write("â€¢ DÃ¼ÅŸÃ¼k performans gÃ¶steren hastalÄ±k sÄ±nÄ±flarÄ± iÃ§in ek eÄŸitim programlarÄ± dÃ¼zenlenebilir\n")
            f.write("â€¢ Deneyim sÃ¼resi ile baÅŸarÄ± oranÄ± arasÄ±ndaki iliÅŸki gÃ¶z Ã¶nÃ¼nde bulundurularak\n")
            f.write("  mezuniyet sonrasÄ± eÄŸitim programlarÄ± optimize edilebilir\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("Rapor Sonu\n")
            f.write("GitHub: https://github.com/arcankc\n")
            f.write("=" * 80 + "\n")

        print(f"âœ… KapsamlÄ± rapor oluÅŸturuldu: {report_path}")

        # JSON formatÄ±nda da kaydet
        self._save_json_results()

    def _save_json_results(self):
        """SonuÃ§larÄ± JSON formatÄ±nda kaydet"""
        json_path = self.output_dir / 'analiz_sonuclari.json'

        results_dict = {
            'timestamp': datetime.now().isoformat(),
            'data_summary': {
                'model_questions': len(self.dp.model_data) if self.dp.model_data is not None else 0,
                'participants': self.dp.participant_data[
                    'participant_id'].nunique() if self.dp.participant_data is not None else 0,
                'total_responses': len(self.dp.participant_data) if self.dp.participant_data is not None else 0
            },
            'analysis_results': self.analyzer.results,
            'config': CONFIG
        }

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, indent=2, ensure_ascii=False, default=str)

        print(f"âœ… JSON sonuÃ§larÄ± kaydedildi: {json_path}")


# =============================================================================
# MAIN ANALYSIS PIPELINE
# =============================================================================
def main():
    """Ana analiz pipeline'Ä±"""
    print("ğŸš€ Dermatoloji Tezi - KapsamlÄ± Veri Analizi BaÅŸlatÄ±lÄ±yor")
    print("=" * 60)
    print(f"ğŸ‘¤ KullanÄ±cÄ±: arcankc")
    print(f"ğŸ“… Tarih: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    print(f"ğŸ¯ Hedef: Model vs Ä°nsan Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    print("=" * 60)

    try:
        # 1. Veri Ä°ÅŸleme
        print("\nğŸ“‚ 1. VERÄ° Ä°ÅLEME AÅAMASI")
        print("-" * 30)

        data_processor = DataProcessor()

        if not data_processor.load_data():
            return False

        data_processor.preprocess_model_data()
        data_processor.preprocess_participant_data()
        data_processor.merge_data()

        # 2. Ä°statistiksel Analiz
        print("\nğŸ“Š 2. Ä°STATÄ°STÄ°KSEL ANALÄ°Z AÅAMASI")
        print("-" * 35)

        analyzer = StatisticalAnalyzer(data_processor)

        analyzer.analyze_overall_performance()
        analyzer.analyze_class_wise_performance()
        analyzer.statistical_tests()
        analyzer.experience_analysis()

        # 3. GÃ¶rselleÅŸtirme
        print("\nğŸ¨ 3. GÃ–RSELLEÅTÄ°RME AÅAMASI")
        print("-" * 30)

        visualizer = Visualizer(data_processor, analyzer)

        visualizer.create_overall_comparison()
        visualizer.create_class_wise_analysis()
        visualizer.create_confusion_matrices()
        visualizer.create_experience_analysis()
        visualizer.create_statistical_summary()

        # 4. Rapor OluÅŸturma
        print("\nğŸ“‹ 4. RAPOR OLUÅTURMA AÅAMASI")
        print("-" * 30)

        report_generator = ReportGenerator(data_processor, analyzer)
        report_generator.generate_comprehensive_report()

        # 5. Ã–zet
        print("\nğŸ‰ ANALÄ°Z TAMAMLANDI!")
        print("=" * 30)
        print(f"ğŸ“ Ã‡Ä±ktÄ± KlasÃ¶rÃ¼: {CONFIG['paths']['output_dir']}")
        print("\nğŸ“Š OluÅŸturulan Dosyalar:")
        print("   ğŸ“ˆ genel_karsilastirma.png - Genel performans karÅŸÄ±laÅŸtÄ±rmasÄ±")
        print("   ğŸ“Š sinif_bazli_analiz.png - HastalÄ±k sÄ±nÄ±fÄ± bazlÄ± analiz")
        print("   ğŸ”„ karisikhk_matrisleri.png - KarÄ±ÅŸÄ±klÄ±k matrisleri")
        print("   ğŸ‘¨â€âš•ï¸ deneyim_analizi.png - Deneyim sÃ¼resi analizi")
        print("   ğŸ“‹ istatistiksel_ozet.png - Ä°statistiksel test sonuÃ§larÄ±")
        print("   ğŸ“„ dermatoloji_tezi_analiz_raporu.txt - KapsamlÄ± metin raporu")
        print("   ğŸ’¾ analiz_sonuclari.json - TÃ¼m sonuÃ§larÄ±n JSON formatÄ±")

        print("\nğŸ” Anahtar Bulgular:")

        # KÄ±sa Ã¶zet gÃ¶ster
        if data_processor.model_data is not None and data_processor.participant_data is not None:
            model_acc = data_processor.model_data['model_correct'].mean()
            human_acc = data_processor.participant_data['is_correct'].mean()
            print(f"   ğŸ¤– Model BaÅŸarÄ± OranÄ±: {model_acc:.3f} ({model_acc * 100:.1f}%)")
            print(f"   ğŸ‘¥ Ä°nsan BaÅŸarÄ± OranÄ±: {human_acc:.3f} ({human_acc * 100:.1f}%)")

            if model_acc > human_acc:
                print(f"   âœ… Model insanlardan {((model_acc - human_acc) / human_acc) * 100:.1f}% daha baÅŸarÄ±lÄ±")
            else:
                print(f"   âœ… Ä°nsanlar modelden {((human_acc - model_acc) / model_acc) * 100:.1f}% daha baÅŸarÄ±lÄ±")

        if 'group' in data_processor.participant_data.columns:
            group_stats = data_processor.participant_data.groupby('group')['is_correct'].mean()
            for group, acc in group_stats.items():
                print(f"   ğŸ‘¨â€âš•ï¸ {group} BaÅŸarÄ± OranÄ±: {acc:.3f} ({acc * 100:.1f}%)")

                print("\nğŸ“š Tez KullanÄ±mÄ±:")
                print("   â€¢ Grafikleri doÄŸrudan tez belgenize ekleyebilirsiniz")
                print("   â€¢ Ä°statistiksel test sonuÃ§larÄ±nÄ± metodoloji bÃ¶lÃ¼mÃ¼nde kullanÄ±n")
                print("   â€¢ KapsamlÄ± raporu bulgular bÃ¶lÃ¼mÃ¼ iÃ§in referans alÄ±n")
                print("   â€¢ JSON dosyasÄ±nÄ± istatistik programlarÄ±nda (R, SPSS) aÃ§abilirsiniz")
                print("   â€¢ SÄ±nÄ±f bazlÄ± analizleri hastalÄ±k spesifik tartÄ±ÅŸmalarda kullanÄ±n")

                print("\nğŸ¯ Sonraki AdÄ±mlar:")
                print("   1. Grafikleri tez formatÄ±na uygun ÅŸekilde dÃ¼zenleyin")
                print("   2. Ä°statistiksel anlamlÄ±lÄ±k sonuÃ§larÄ±nÄ± yorumlayÄ±n")
                print("   3. Model performansÄ±nÄ±n klinik etkileri Ã¼zerine tartÄ±ÅŸÄ±n")
                print("   4. Deneyim sÃ¼resi bulgularÄ±nÄ± eÄŸitim programlarÄ± iÃ§in Ã¶nerilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n")
                print("   5. SÄ±nÄ±rlÄ±lÄ±klar ve gelecek Ã§alÄ±ÅŸmalar bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¼ncelleyin")

                print("\nğŸ”¬ Ä°statistiksel AnlamlÄ±lÄ±k Rehberi:")
                print("   â€¢ p < 0.05: Ä°statistiksel olarak anlamlÄ±")
                print("   â€¢ p < 0.01: YÃ¼ksek anlamlÄ±lÄ±k seviyesi")
                print("   â€¢ p < 0.001: Ã‡ok yÃ¼ksek anlamlÄ±lÄ±k seviyesi")
                print("   â€¢ Cohen's Kappa > 0.6: Ä°yi uyuÅŸma")
                print("   â€¢ AUC > 0.8: MÃ¼kemmel sÄ±nÄ±flandÄ±rma performansÄ±")

                print("\nğŸ“– Tez BÃ¶lÃ¼mleri iÃ§in Ã–neriler:")
                print("   ğŸ“Š Bulgular:")
                print("      - Genel karÅŸÄ±laÅŸtÄ±rma grafiÄŸini ana bulgular olarak sunun")
                print("      - SÄ±nÄ±f bazlÄ± analizi detaylÄ± bulgular bÃ¶lÃ¼mÃ¼nde kullanÄ±n")
                print("      - Ä°statistiksel test sonuÃ§larÄ±nÄ± tablolar halinde verin")
                print("   ğŸ” TartÄ±ÅŸma:")
                print("      - Model vs uzman karÅŸÄ±laÅŸtÄ±rmasÄ±nÄ± literatÃ¼r ile destekleyin")
                print("      - Deneyim etkisini mevcut eÄŸitim sistemleri ile iliÅŸkilendirin")
                print("      - Klinik kullanÄ±m potansiyelini vurgulayÄ±n")
                print("   ğŸ“š SonuÃ§:")
                print("      - Ana bulgularÄ± Ã¶zetleyin")
                print("      - Klinik Ã¶neriler getirin")
                print("      - Gelecek araÅŸtÄ±rma alanlarÄ±nÄ± belirtin")

                print(f"\nğŸ“ Destek ve Ä°letiÅŸim:")
                print(f"   GitHub: https://github.com/arcankc")
                print(f"   Aktif Repolar:")
                print(f"      â€¢ StackedRealTest - Test seti analizleri")
                print(f"      â€¢ Swin_Tiny_85.84f1- - Swin Transformer modeli")
                print(f"      â€¢ StackedQuizTest - Quiz test analizleri")
                print(f"      â€¢ EfficientNet_V2_m - EfficientNet V2 modeli")
                print(f"      â€¢ Deit-iii - DeiT III implementasyonu")

                return True

            except Exception as e:
                print(f"\nâŒ ANALIZ HATASI: {e}")
                import traceback
                traceback.print_exc()
                return False

    # =============================================================================
    # ADDITIONAL UTILITY FUNCTIONS
    # =============================================================================

    def validate_data_files():
        """Veri dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et"""
        print("\nğŸ” Veri dosyalarÄ± kontrol ediliyor...")

        model_path = Path(CONFIG['paths']['model_results'])
        participant_path = Path(CONFIG['paths']['participant_results'])

        issues = []

        if not model_path.exists():
            issues.append(f"âŒ Model sonuÃ§larÄ± bulunamadÄ±: {model_path}")
        else:
            print(f"âœ… Model sonuÃ§larÄ± mevcut: {model_path}")

        if not participant_path.exists():
            issues.append(f"âŒ KatÄ±lÄ±mcÄ± sonuÃ§larÄ± bulunamadÄ±: {participant_path}")
        else:
            print(f"âœ… KatÄ±lÄ±mcÄ± sonuÃ§larÄ± mevcut: {participant_path}")

        # Output directory kontrolÃ¼
        output_dir = Path(CONFIG['paths']['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… Ã‡Ä±ktÄ± klasÃ¶rÃ¼ hazÄ±r: {output_dir}")

        if issues:
            print("\nâš ï¸ UYARI: BazÄ± dosyalar eksik!")
            for issue in issues:
                print(f"   {issue}")
            print("\nğŸ’¡ Ã‡Ã¶zÃ¼m Ã¶nerileri:")
            print("   â€¢ Dosya yollarÄ±nÄ± CONFIG bÃ¶lÃ¼mÃ¼nden kontrol edin")
            print("   â€¢ Dosya isimlerinin doÄŸru olduÄŸundan emin olun")
            print("   â€¢ Dosya izinlerini kontrol edin")
            return False

        return True

    def create_sample_data():
        """Ã–rnek veri dosyalarÄ± oluÅŸtur (test amaÃ§lÄ±)"""
        print("\nğŸ”§ Ã–rnek veri dosyalarÄ± oluÅŸturuluyor...")

        # Ã–rnek model sonuÃ§larÄ±
        model_sample = pd.DataFrame({
            'question_id': [f'Q{i:03d}' for i in range(1, 81)],
            'image_id': [f'ISIC_{i:07d}' for i in range(1000000, 1000080)],
            'true_class': np.random.choice(list(CONFIG['classes'].keys()), 80),
            'model_correct': np.random.choice([True, False], 80, p=[0.75, 0.25]),
            'CNN + TTA_correct': np.random.choice([True, False], 80, p=[0.78, 0.22]),
            'LightGBM_correct': np.random.choice([True, False], 80, p=[0.73, 0.27])
        })

        # Ã–rnek katÄ±lÄ±mcÄ± sonuÃ§larÄ±
        participants = []
        for participant_id in range(1, 21):  # 20 katÄ±lÄ±mcÄ±
            experience_level = np.random.choice(['Uzman Dr.', 'Asistan Dr.', 'Prof. Dr.', 'DoÃ§. Dr.'])
            experience_years = np.random.randint(1, 20)

            for question_id in range(1, 81):  # 80 soru
                correct_answer = np.random.choice(list(CONFIG['classes'].keys()))
                # Uzmanlar daha baÅŸarÄ±lÄ±
                success_prob = 0.8 if 'Uzman' in experience_level or 'Prof' in experience_level or 'DoÃ§' in experience_level else 0.6
                is_correct = np.random.choice([True, False], p=[success_prob, 1 - success_prob])
                participant_answer = correct_answer if is_correct else np.random.choice(list(CONFIG['classes'].keys()))

                participants.append({
                    'participant_id': f'P{participant_id:03d}',
                    'question_id': f'Q{question_id:03d}',
                    'participant_answer': participant_answer,
                    'correct_answer': correct_answer,
                    'is_correct': is_correct,
                    'experience_level': experience_level,
                    'experience_years': experience_years
                })

        participant_sample = pd.DataFrame(participants)

        # DosyalarÄ± kaydet
        sample_dir = Path(CONFIG['paths']['base_dir']) / 'sample_data'
        sample_dir.mkdir(exist_ok=True)

        model_sample.to_csv(sample_dir / 'sample_detailed_results.csv', index=False)
        participant_sample.to_excel(sample_dir / 'sample_quiz_results.xlsx', index=False)

        print(f"âœ… Ã–rnek veri dosyalarÄ± oluÅŸturuldu: {sample_dir}")
        print("ğŸ’¡ GerÃ§ek verilerinizi kullanmak iÃ§in CONFIG bÃ¶lÃ¼mÃ¼ndeki yollarÄ± gÃ¼ncelleyin")

    def print_system_requirements():
        """Sistem gereksinimlerini yazdÄ±r"""
        print("\nğŸ“‹ SÄ°STEM GEREKSÄ°NÄ°MLERÄ°:")
        print("-" * 30)

        required_packages = [
            'pandas', 'numpy', 'matplotlib', 'seaborn', 'scipy',
            'statsmodels', 'scikit-learn', 'openpyxl'
        ]

        print("Gerekli Python Paketleri:")
        for package in required_packages:
            try:
                __import__(package)
                print(f"   âœ… {package}")
            except ImportError:
                print(f"   âŒ {package} - YÃ¼klenmemiÅŸ!")
                print(f"      YÃ¼klemek iÃ§in: pip install {package}")

        print("\nDosya Format Gereksinimleri:")
        print("   ğŸ“„ Model SonuÃ§larÄ±: CSV formatÄ±nda")
        print("      - Gerekli sÃ¼tunlar: question_id, model_correct, true_class")
        print("   ğŸ“Š KatÄ±lÄ±mcÄ± SonuÃ§larÄ±: Excel formatÄ±nda")
        print("      - Gerekli sÃ¼tunlar: participant_id, question_id, is_correct")
        print("      - Ä°steÄŸe baÄŸlÄ±: experience_level, experience_years")

    def create_readme():
        """README dosyasÄ± oluÅŸtur"""
        readme_path = Path(CONFIG['paths']['output_dir']) / 'README.md'

        readme_content = """# Dermatoloji UzmanlÄ±k Tezi - Veri Analizi SonuÃ§larÄ±

        ## ğŸ“Š Analiz Ã–zeti
        Bu klasÃ¶r, dermatoloji uzmanlÄ±k tezinde kullanÄ±lan AI model performansÄ± ile insan uzman performansÄ± karÅŸÄ±laÅŸtÄ±rma analizinin sonuÃ§larÄ±nÄ± iÃ§ermektedir.

        ## ğŸ“ Dosya AÃ§Ä±klamalarÄ±

        ### ğŸ“ˆ Grafikler
        - `genel_karsilastirma.png` - Model vs Ä°nsan genel performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        - `sinif_bazli_analiz.png` - HastalÄ±k sÄ±nÄ±fÄ± bazlÄ± detaylÄ± analiz
        - `karisikhk_matrisleri.png` - Model, uzman ve asistan karÄ±ÅŸÄ±klÄ±k matrisleri
        - `deneyim_analizi.png` - Deneyim sÃ¼resi ile baÅŸarÄ± oranÄ± iliÅŸkisi
        - `istatistiksel_ozet.png` - Ä°statistiksel test sonuÃ§larÄ± tablosu

        ### ğŸ“„ Raporlar
        - `dermatoloji_tezi_analiz_raporu.txt` - KapsamlÄ± analiz raporu
        - `analiz_sonuclari.json` - TÃ¼m sonuÃ§larÄ±n JSON formatÄ±
        - `README.md` - Bu dosya

        ## ğŸ” Ana Bulgular

        ### Model vs Ä°nsan KarÅŸÄ±laÅŸtÄ±rmasÄ±
        - AI modelin genel baÅŸarÄ± oranÄ±
        - Ä°nsan uzmanlarÄ±n ortalama baÅŸarÄ± oranÄ±
        - Ä°statistiksel anlamlÄ±lÄ±k testi sonuÃ§larÄ±

        ### Uzman vs Asistan Analizi
        - Deneyim seviyesi ile performans iliÅŸkisi
        - HastalÄ±k sÄ±nÄ±fÄ± bazlÄ± performans farklarÄ±
        - Ä°statistiksel karÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ±

        ### SÄ±nÄ±f BazlÄ± Performans
        - Her hastalÄ±k sÄ±nÄ±fÄ± iÃ§in ayrÄ± analiz
        - Model, uzman ve asistan performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        - Zorluk seviyesi analizi

        ## ğŸ“š Tez KullanÄ±mÄ±
        Bu sonuÃ§lar doÄŸrudan tez belgelerinde kullanÄ±labilir:
        - Grafikler â†’ Bulgular bÃ¶lÃ¼mÃ¼
        - Ä°statistiksel sonuÃ§lar â†’ Metodoloji ve bulgular
        - KapsamlÄ± rapor â†’ TartÄ±ÅŸma bÃ¶lÃ¼mÃ¼ referansÄ±

        ## ğŸ”— Ä°letiÅŸim
        - GitHub: https://github.com/arcankc
        - Tarih: """ + datetime.now().strftime('%d.%m.%Y') + """
        - Versiyon: 1.0.0

        ## ğŸ“– KullanÄ±m LisansÄ±
        Bu analiz sonuÃ§larÄ± dermatoloji uzmanlÄ±k tezi kapsamÄ±nda akademik kullanÄ±m iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.
        """

        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)

        print(f"âœ… README dosyasÄ± oluÅŸturuldu: {readme_path}")


# =============================================================================
# MAIN EXECUTION
# =============================================================================
if __name__ == "__main__":
    print("ğŸš€ Dermatoloji UzmanlÄ±k Tezi - KapsamlÄ± Veri Analizi Sistemi")
    print(f"ğŸ‘¤ GeliÅŸtirici: arcankc (GitHub: https://github.com/arcankc)")
    print(f"ğŸ“… Tarih: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    print(f"ğŸ¥ AmaÃ§: AI Model vs Ä°nsan Uzman Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")

    # Sistem gereksinimlerini kontrol et
    print_system_requirements()

    # Veri dosyalarÄ±nÄ± kontrol et
    if not validate_data_files():
        print("\nâ“ Ã–rnek veri dosyalarÄ± oluÅŸturulsun mu? (y/n)")
        choice = input().lower().strip()
        if choice in ['y', 'yes', 'e', 'evet']:
            create_sample_data()
            print("\nğŸ’¡ Ã–rnek veriler oluÅŸturuldu. GerÃ§ek verilerinizle deÄŸiÅŸtirmeyi unutmayÄ±n!")
        else:
            print("\nâš ï¸ LÃ¼tfen veri dosyalarÄ±nÄ± kontrol edin ve tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.")
            exit(1)

    # Ana analizi Ã§alÄ±ÅŸtÄ±r
    success = main()

    if success:
        # README dosyasÄ± oluÅŸtur
        create_readme()

        print("\nğŸ‰ TÃœM ANALÄ°ZLER BAÅARIYLA TAMAMLANDI!")
        print("=" * 50)
        print("ğŸ“Š Dermatoloji teziniz iÃ§in hazÄ±r:")
        print("   â€¢ YÃ¼ksek kaliteli grafikler")
        print("   â€¢ Ä°statistiksel test sonuÃ§larÄ±")
        print("   â€¢ KapsamlÄ± analiz raporlarÄ±")
        print("   â€¢ JSON veri formatlarÄ±")
        print("   â€¢ KullanÄ±m kÄ±lavuzu (README)")

        print("\nğŸ† Tez BaÅŸarÄ± Ä°puÃ§larÄ±:")
        print("   âœ¨ Grafikleri yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼kle kaydedin (300 DPI)")
        print("   ğŸ“ Ä°statistiksel sonuÃ§larÄ± metodoloji bÃ¶lÃ¼mÃ¼nde aÃ§Ä±klayÄ±n")
        print("   ğŸ” BulgularÄ±nÄ±zÄ± literatÃ¼r ile destekleyin")
        print("   ğŸ’¡ Klinik Ã¶nerilerinizi sonuÃ§ bÃ¶lÃ¼mÃ¼nde vurgulayÄ±n")
        print("   ğŸ¯ Gelecek Ã§alÄ±ÅŸmalar iÃ§in yÃ¶n belirleyin")

        print(f"\nğŸ“ TÃ¼m dosyalar hazÄ±r: {CONFIG['paths']['output_dir']}")
        print("ğŸ“ Tez yazÄ±mÄ±nda baÅŸarÄ±lar dileriz!")

    else:
        print("\nğŸ’¥ Analiz baÅŸarÄ±sÄ±z oldu!")
        print("ğŸ”§ Hata mesajlarÄ±nÄ± kontrol edin ve gerekli dÃ¼zeltmeleri yapÄ±n.")
        print("ğŸ’¬ GitHub Ã¼zerinden destek alabilirsiniz: https://github.com/arcankc")